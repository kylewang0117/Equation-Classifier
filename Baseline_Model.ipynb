{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Pulling the data from drive"
      ],
      "metadata": {
        "id": "KuLF0yFjTwi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "from google.colab import drive\n",
        "from PIL import Image, ImageOps\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy54_y3uXUPT",
        "outputId": "5419917c-a9f9-4992-b92c-17fd0810cc4e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.PILToTensor()])\n",
        "\n",
        "def manual_pull(iterable, indices):\n",
        "    output=[]\n",
        "    for i in indices:\n",
        "        image=ImageOps.grayscale(iterable[i][0])\n",
        "        image=transform(image)/255\n",
        "        label=iterable[i][1]\n",
        "        output.append((image,label))\n",
        "    return output\n",
        "\n",
        "classifier_dir=\"/content/drive/MyDrive/APS360 Group Project/Classified HMEs\" #Temp model training data\n",
        "classifier_data=torchvision.datasets.ImageFolder(classifier_dir)"
      ],
      "metadata": {
        "id": "JGBHTD0hTpIz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classifier_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObEPTJaiTqJJ",
        "outputId": "f19f9c2c-5e7c-491f-f8c2-6e79a1c0da0f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 920\n",
            "    Root location: /content/drive/MyDrive/APS360 Group Project/Classified HMEs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(60) #Was 50 before\n",
        "data_len=len(classifier_data)\n",
        "indices=list(range(data_len))\n",
        "np.random.shuffle(indices)\n",
        "train_indices=indices[:840]\n",
        "val_indices=indices[840:920]\n",
        "\n",
        "train_c_set = manual_pull(classifier_data,train_indices)\n",
        "val_c_set = manual_pull(classifier_data,val_indices)\n",
        "\n",
        "img_to_tensor = transforms.ToTensor()"
      ],
      "metadata": {
        "id": "BKTpxVqXTs2d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline Model"
      ],
      "metadata": {
        "id": "Ubk7taJETzsV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uPVp_jDlTPs1"
      },
      "outputs": [],
      "source": [
        "class BaselineModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaselineModel, self).__init__()\n",
        "        self.layer1 = nn.Linear(520*173, 3000)\n",
        "        self.layer2 = nn.Linear(3000, 200)\n",
        "        self.layer3 = nn.Linear(200, 9)\n",
        "    def forward(self, img):\n",
        "        flattened = img.view(-1, 520*173)\n",
        "        activation1 = F.relu(self.layer1(flattened))\n",
        "        activation2 = F.relu(self.layer2(activation1))\n",
        "        output = self.layer3(activation2)\n",
        "        return output\n",
        "\n",
        "model = BaselineModel()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(data, model):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in torch.utils.data.DataLoader(data):\n",
        "        output = model(imgs) \n",
        "        #Puts the image through the model, one at a time, gets an output of a size 10 vector\n",
        "        #select index with maximum prediction score\n",
        "        pred = output.max(1, keepdim=True)[1] \n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "mueA9tODX-44"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_base(model, train_data, val_data, epochs=100, learning_rate=0.0005):\n",
        "    criterion=nn.CrossEntropyLoss()\n",
        "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "    outputs=[]\n",
        "    \n",
        "    train_batch=torch.utils.data.DataLoader(train_data, 40)\n",
        "    val_batch=torch.utils.data.DataLoader(val_data, 40)\n",
        "\n",
        "    one_hot_encoding=torch.eye(9)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        batch_no=0\n",
        "        total_loss=0\n",
        "        for imgs, label in train_batch:\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            label=one_hot_encoding[label]\n",
        "\n",
        "            out=model(imgs)\n",
        "            loss=criterion(out, label)\n",
        "            #print(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss=total_loss+loss\n",
        "            batch_no+=1\n",
        "\n",
        "        train_acc=get_accuracy(train_data, model)\n",
        "        val_acc=get_accuracy(val_data, model)\n",
        "\n",
        "        print('Epoch:{}, Loss:{:.4f}, Train accuracy:{:.4f}, Validation accuracy:{:.4f}'.format(epoch+1, float(total_loss/batch_no), train_acc, val_acc))\n",
        "        outputs.append((epoch, total_loss/batch_no, train_acc, val_acc))\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "R3t6k1CrTX8P"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_base(model, train_data=train_c_set, val_data=val_c_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUehz3XJ9rnm",
        "outputId": "e4cf682d-8521-4bef-d8fb-39483bcf3584"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1, Loss:2.1840, Train accuracy:0.1345, Validation accuracy:0.1625\n",
            "Epoch:2, Loss:2.2113, Train accuracy:0.1345, Validation accuracy:0.1625\n",
            "Epoch:3, Loss:2.1910, Train accuracy:0.1345, Validation accuracy:0.1625\n",
            "Epoch:4, Loss:2.1906, Train accuracy:0.1345, Validation accuracy:0.1625\n",
            "Epoch:5, Loss:2.1814, Train accuracy:0.1345, Validation accuracy:0.1625\n",
            "Epoch:6, Loss:2.1762, Train accuracy:0.1345, Validation accuracy:0.1625\n",
            "Epoch:7, Loss:2.1695, Train accuracy:0.1845, Validation accuracy:0.1625\n",
            "Epoch:8, Loss:2.1594, Train accuracy:0.1607, Validation accuracy:0.1625\n",
            "Epoch:9, Loss:2.1532, Train accuracy:0.1429, Validation accuracy:0.1625\n",
            "Epoch:10, Loss:2.1450, Train accuracy:0.1857, Validation accuracy:0.1625\n",
            "Epoch:11, Loss:2.1359, Train accuracy:0.2167, Validation accuracy:0.1875\n",
            "Epoch:12, Loss:2.1252, Train accuracy:0.2226, Validation accuracy:0.2000\n",
            "Epoch:13, Loss:2.1155, Train accuracy:0.2298, Validation accuracy:0.2125\n",
            "Epoch:14, Loss:2.1033, Train accuracy:0.2286, Validation accuracy:0.2000\n",
            "Epoch:15, Loss:2.0898, Train accuracy:0.2476, Validation accuracy:0.2000\n",
            "Epoch:16, Loss:2.0758, Train accuracy:0.2643, Validation accuracy:0.2250\n",
            "Epoch:17, Loss:2.0629, Train accuracy:0.2667, Validation accuracy:0.2125\n",
            "Epoch:18, Loss:2.0476, Train accuracy:0.3143, Validation accuracy:0.2500\n",
            "Epoch:19, Loss:2.0304, Train accuracy:0.2929, Validation accuracy:0.2125\n",
            "Epoch:20, Loss:2.0111, Train accuracy:0.3619, Validation accuracy:0.2500\n",
            "Epoch:21, Loss:1.9880, Train accuracy:0.3881, Validation accuracy:0.2750\n",
            "Epoch:22, Loss:1.9681, Train accuracy:0.4357, Validation accuracy:0.3000\n",
            "Epoch:23, Loss:1.9451, Train accuracy:0.4500, Validation accuracy:0.3000\n",
            "Epoch:24, Loss:1.9222, Train accuracy:0.5238, Validation accuracy:0.3000\n",
            "Epoch:25, Loss:1.8970, Train accuracy:0.5405, Validation accuracy:0.2750\n",
            "Epoch:26, Loss:1.8716, Train accuracy:0.4988, Validation accuracy:0.2500\n",
            "Epoch:27, Loss:1.8451, Train accuracy:0.4655, Validation accuracy:0.2000\n",
            "Epoch:28, Loss:1.8208, Train accuracy:0.4631, Validation accuracy:0.2125\n",
            "Epoch:29, Loss:1.7928, Train accuracy:0.4226, Validation accuracy:0.2375\n",
            "Epoch:30, Loss:1.7599, Train accuracy:0.4179, Validation accuracy:0.2500\n",
            "Epoch:31, Loss:1.7230, Train accuracy:0.4000, Validation accuracy:0.2375\n",
            "Epoch:32, Loss:1.6834, Train accuracy:0.3917, Validation accuracy:0.2250\n",
            "Epoch:33, Loss:1.6419, Train accuracy:0.4476, Validation accuracy:0.2250\n",
            "Epoch:34, Loss:1.5959, Train accuracy:0.4964, Validation accuracy:0.2375\n",
            "Epoch:35, Loss:1.5562, Train accuracy:0.5405, Validation accuracy:0.2375\n",
            "Epoch:36, Loss:1.5129, Train accuracy:0.5619, Validation accuracy:0.2875\n",
            "Epoch:37, Loss:1.4680, Train accuracy:0.5560, Validation accuracy:0.3125\n",
            "Epoch:38, Loss:1.4156, Train accuracy:0.5440, Validation accuracy:0.2750\n",
            "Epoch:39, Loss:1.3646, Train accuracy:0.5548, Validation accuracy:0.2750\n",
            "Epoch:40, Loss:1.3101, Train accuracy:0.6048, Validation accuracy:0.3000\n",
            "Epoch:41, Loss:1.2625, Train accuracy:0.6464, Validation accuracy:0.3250\n",
            "Epoch:42, Loss:1.2161, Train accuracy:0.6488, Validation accuracy:0.3125\n",
            "Epoch:43, Loss:1.1739, Train accuracy:0.6476, Validation accuracy:0.3125\n",
            "Epoch:44, Loss:1.1363, Train accuracy:0.6452, Validation accuracy:0.3000\n",
            "Epoch:45, Loss:1.1049, Train accuracy:0.6357, Validation accuracy:0.3000\n",
            "Epoch:46, Loss:1.0702, Train accuracy:0.6167, Validation accuracy:0.3375\n",
            "Epoch:47, Loss:1.0292, Train accuracy:0.6333, Validation accuracy:0.3250\n",
            "Epoch:48, Loss:0.9789, Train accuracy:0.6881, Validation accuracy:0.3500\n",
            "Epoch:49, Loss:0.9297, Train accuracy:0.7440, Validation accuracy:0.3875\n",
            "Epoch:50, Loss:0.8827, Train accuracy:0.7881, Validation accuracy:0.4000\n",
            "Epoch:51, Loss:0.8430, Train accuracy:0.8083, Validation accuracy:0.4000\n",
            "Epoch:52, Loss:0.8021, Train accuracy:0.8321, Validation accuracy:0.4125\n",
            "Epoch:53, Loss:0.7634, Train accuracy:0.8595, Validation accuracy:0.4250\n",
            "Epoch:54, Loss:0.7248, Train accuracy:0.8667, Validation accuracy:0.4125\n",
            "Epoch:55, Loss:0.6810, Train accuracy:0.8821, Validation accuracy:0.4500\n",
            "Epoch:56, Loss:0.6399, Train accuracy:0.8964, Validation accuracy:0.4625\n",
            "Epoch:57, Loss:0.6013, Train accuracy:0.9143, Validation accuracy:0.4875\n",
            "Epoch:58, Loss:0.5653, Train accuracy:0.9179, Validation accuracy:0.4750\n",
            "Epoch:59, Loss:0.5334, Train accuracy:0.9286, Validation accuracy:0.4750\n",
            "Epoch:60, Loss:0.5052, Train accuracy:0.9393, Validation accuracy:0.4625\n",
            "Epoch:61, Loss:0.4834, Train accuracy:0.9429, Validation accuracy:0.4625\n",
            "Epoch:62, Loss:0.4658, Train accuracy:0.9393, Validation accuracy:0.4750\n",
            "Epoch:63, Loss:0.4524, Train accuracy:0.9107, Validation accuracy:0.4375\n",
            "Epoch:64, Loss:0.4444, Train accuracy:0.8798, Validation accuracy:0.3875\n",
            "Epoch:65, Loss:0.4413, Train accuracy:0.8524, Validation accuracy:0.3875\n",
            "Epoch:66, Loss:0.4422, Train accuracy:0.8286, Validation accuracy:0.3875\n",
            "Epoch:67, Loss:0.4476, Train accuracy:0.8238, Validation accuracy:0.3750\n",
            "Epoch:68, Loss:0.4644, Train accuracy:0.8238, Validation accuracy:0.3625\n",
            "Epoch:69, Loss:0.5035, Train accuracy:0.8262, Validation accuracy:0.3625\n",
            "Epoch:70, Loss:0.6283, Train accuracy:0.9024, Validation accuracy:0.4250\n",
            "Epoch:71, Loss:0.7302, Train accuracy:0.7095, Validation accuracy:0.3750\n",
            "Epoch:72, Loss:0.6921, Train accuracy:0.9155, Validation accuracy:0.4125\n",
            "Epoch:73, Loss:0.7824, Train accuracy:0.5583, Validation accuracy:0.3500\n",
            "Epoch:74, Loss:0.8554, Train accuracy:0.5881, Validation accuracy:0.3500\n",
            "Epoch:75, Loss:0.9833, Train accuracy:0.6452, Validation accuracy:0.2375\n",
            "Epoch:76, Loss:0.6954, Train accuracy:0.6214, Validation accuracy:0.2750\n",
            "Epoch:77, Loss:0.7996, Train accuracy:0.7321, Validation accuracy:0.4375\n",
            "Epoch:78, Loss:0.7731, Train accuracy:0.8536, Validation accuracy:0.3500\n",
            "Epoch:79, Loss:0.5157, Train accuracy:0.9024, Validation accuracy:0.4000\n",
            "Epoch:80, Loss:0.3760, Train accuracy:0.9536, Validation accuracy:0.4125\n",
            "Epoch:81, Loss:0.2977, Train accuracy:0.9762, Validation accuracy:0.5000\n",
            "Epoch:82, Loss:0.2792, Train accuracy:0.9762, Validation accuracy:0.4500\n",
            "Epoch:83, Loss:0.2795, Train accuracy:0.9393, Validation accuracy:0.4125\n",
            "Epoch:84, Loss:0.2722, Train accuracy:0.9405, Validation accuracy:0.3750\n",
            "Epoch:85, Loss:0.2683, Train accuracy:0.8560, Validation accuracy:0.3500\n",
            "Epoch:86, Loss:0.3147, Train accuracy:0.8798, Validation accuracy:0.4125\n",
            "Epoch:87, Loss:0.3643, Train accuracy:0.6369, Validation accuracy:0.3125\n",
            "Epoch:88, Loss:0.5919, Train accuracy:0.7298, Validation accuracy:0.3125\n",
            "Epoch:89, Loss:0.5265, Train accuracy:0.8202, Validation accuracy:0.5000\n",
            "Epoch:90, Loss:0.6221, Train accuracy:0.7667, Validation accuracy:0.4000\n",
            "Epoch:91, Loss:0.5683, Train accuracy:0.8702, Validation accuracy:0.3875\n",
            "Epoch:92, Loss:0.3716, Train accuracy:0.8702, Validation accuracy:0.4125\n",
            "Epoch:93, Loss:0.4029, Train accuracy:0.9238, Validation accuracy:0.3750\n",
            "Epoch:94, Loss:0.7844, Train accuracy:0.8881, Validation accuracy:0.4375\n",
            "Epoch:95, Loss:0.6507, Train accuracy:0.7512, Validation accuracy:0.3875\n",
            "Epoch:96, Loss:0.7103, Train accuracy:0.9440, Validation accuracy:0.4750\n",
            "Epoch:97, Loss:0.3907, Train accuracy:0.8155, Validation accuracy:0.4875\n",
            "Epoch:98, Loss:0.8575, Train accuracy:0.7060, Validation accuracy:0.3750\n",
            "Epoch:99, Loss:1.0462, Train accuracy:0.6774, Validation accuracy:0.5000\n",
            "Epoch:100, Loss:0.8881, Train accuracy:0.9131, Validation accuracy:0.4500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, tensor(2.1840, grad_fn=<DivBackward0>), 0.13452380952380952, 0.1625),\n",
              " (1, tensor(2.2113, grad_fn=<DivBackward0>), 0.13452380952380952, 0.1625),\n",
              " (2, tensor(2.1910, grad_fn=<DivBackward0>), 0.13452380952380952, 0.1625),\n",
              " (3, tensor(2.1906, grad_fn=<DivBackward0>), 0.13452380952380952, 0.1625),\n",
              " (4, tensor(2.1814, grad_fn=<DivBackward0>), 0.13452380952380952, 0.1625),\n",
              " (5, tensor(2.1762, grad_fn=<DivBackward0>), 0.13452380952380952, 0.1625),\n",
              " (6, tensor(2.1695, grad_fn=<DivBackward0>), 0.18452380952380953, 0.1625),\n",
              " (7, tensor(2.1594, grad_fn=<DivBackward0>), 0.16071428571428573, 0.1625),\n",
              " (8, tensor(2.1532, grad_fn=<DivBackward0>), 0.14285714285714285, 0.1625),\n",
              " (9, tensor(2.1450, grad_fn=<DivBackward0>), 0.18571428571428572, 0.1625),\n",
              " (10, tensor(2.1359, grad_fn=<DivBackward0>), 0.21666666666666667, 0.1875),\n",
              " (11, tensor(2.1252, grad_fn=<DivBackward0>), 0.2226190476190476, 0.2),\n",
              " (12, tensor(2.1155, grad_fn=<DivBackward0>), 0.22976190476190475, 0.2125),\n",
              " (13, tensor(2.1033, grad_fn=<DivBackward0>), 0.22857142857142856, 0.2),\n",
              " (14, tensor(2.0898, grad_fn=<DivBackward0>), 0.24761904761904763, 0.2),\n",
              " (15, tensor(2.0758, grad_fn=<DivBackward0>), 0.2642857142857143, 0.225),\n",
              " (16, tensor(2.0629, grad_fn=<DivBackward0>), 0.26666666666666666, 0.2125),\n",
              " (17, tensor(2.0476, grad_fn=<DivBackward0>), 0.3142857142857143, 0.25),\n",
              " (18, tensor(2.0304, grad_fn=<DivBackward0>), 0.29285714285714287, 0.2125),\n",
              " (19, tensor(2.0111, grad_fn=<DivBackward0>), 0.3619047619047619, 0.25),\n",
              " (20, tensor(1.9880, grad_fn=<DivBackward0>), 0.3880952380952381, 0.275),\n",
              " (21, tensor(1.9681, grad_fn=<DivBackward0>), 0.4357142857142857, 0.3),\n",
              " (22, tensor(1.9451, grad_fn=<DivBackward0>), 0.45, 0.3),\n",
              " (23, tensor(1.9222, grad_fn=<DivBackward0>), 0.5238095238095238, 0.3),\n",
              " (24, tensor(1.8970, grad_fn=<DivBackward0>), 0.5404761904761904, 0.275),\n",
              " (25, tensor(1.8716, grad_fn=<DivBackward0>), 0.4988095238095238, 0.25),\n",
              " (26, tensor(1.8451, grad_fn=<DivBackward0>), 0.4654761904761905, 0.2),\n",
              " (27, tensor(1.8208, grad_fn=<DivBackward0>), 0.4630952380952381, 0.2125),\n",
              " (28, tensor(1.7928, grad_fn=<DivBackward0>), 0.4226190476190476, 0.2375),\n",
              " (29, tensor(1.7599, grad_fn=<DivBackward0>), 0.41785714285714287, 0.25),\n",
              " (30, tensor(1.7230, grad_fn=<DivBackward0>), 0.4, 0.2375),\n",
              " (31, tensor(1.6834, grad_fn=<DivBackward0>), 0.39166666666666666, 0.225),\n",
              " (32, tensor(1.6419, grad_fn=<DivBackward0>), 0.44761904761904764, 0.225),\n",
              " (33, tensor(1.5959, grad_fn=<DivBackward0>), 0.49642857142857144, 0.2375),\n",
              " (34, tensor(1.5562, grad_fn=<DivBackward0>), 0.5404761904761904, 0.2375),\n",
              " (35, tensor(1.5129, grad_fn=<DivBackward0>), 0.5619047619047619, 0.2875),\n",
              " (36, tensor(1.4680, grad_fn=<DivBackward0>), 0.555952380952381, 0.3125),\n",
              " (37, tensor(1.4156, grad_fn=<DivBackward0>), 0.544047619047619, 0.275),\n",
              " (38, tensor(1.3646, grad_fn=<DivBackward0>), 0.5547619047619048, 0.275),\n",
              " (39, tensor(1.3101, grad_fn=<DivBackward0>), 0.6047619047619047, 0.3),\n",
              " (40, tensor(1.2625, grad_fn=<DivBackward0>), 0.6464285714285715, 0.325),\n",
              " (41, tensor(1.2161, grad_fn=<DivBackward0>), 0.6488095238095238, 0.3125),\n",
              " (42, tensor(1.1739, grad_fn=<DivBackward0>), 0.6476190476190476, 0.3125),\n",
              " (43, tensor(1.1363, grad_fn=<DivBackward0>), 0.6452380952380953, 0.3),\n",
              " (44, tensor(1.1049, grad_fn=<DivBackward0>), 0.6357142857142857, 0.3),\n",
              " (45, tensor(1.0702, grad_fn=<DivBackward0>), 0.6166666666666667, 0.3375),\n",
              " (46, tensor(1.0292, grad_fn=<DivBackward0>), 0.6333333333333333, 0.325),\n",
              " (47, tensor(0.9789, grad_fn=<DivBackward0>), 0.6880952380952381, 0.35),\n",
              " (48, tensor(0.9297, grad_fn=<DivBackward0>), 0.7440476190476191, 0.3875),\n",
              " (49, tensor(0.8827, grad_fn=<DivBackward0>), 0.7880952380952381, 0.4),\n",
              " (50, tensor(0.8430, grad_fn=<DivBackward0>), 0.8083333333333333, 0.4),\n",
              " (51, tensor(0.8021, grad_fn=<DivBackward0>), 0.8321428571428572, 0.4125),\n",
              " (52, tensor(0.7634, grad_fn=<DivBackward0>), 0.8595238095238096, 0.425),\n",
              " (53, tensor(0.7248, grad_fn=<DivBackward0>), 0.8666666666666667, 0.4125),\n",
              " (54, tensor(0.6810, grad_fn=<DivBackward0>), 0.8821428571428571, 0.45),\n",
              " (55, tensor(0.6399, grad_fn=<DivBackward0>), 0.8964285714285715, 0.4625),\n",
              " (56, tensor(0.6013, grad_fn=<DivBackward0>), 0.9142857142857143, 0.4875),\n",
              " (57, tensor(0.5653, grad_fn=<DivBackward0>), 0.9178571428571428, 0.475),\n",
              " (58, tensor(0.5334, grad_fn=<DivBackward0>), 0.9285714285714286, 0.475),\n",
              " (59, tensor(0.5052, grad_fn=<DivBackward0>), 0.9392857142857143, 0.4625),\n",
              " (60, tensor(0.4834, grad_fn=<DivBackward0>), 0.9428571428571428, 0.4625),\n",
              " (61, tensor(0.4658, grad_fn=<DivBackward0>), 0.9392857142857143, 0.475),\n",
              " (62, tensor(0.4524, grad_fn=<DivBackward0>), 0.9107142857142857, 0.4375),\n",
              " (63, tensor(0.4444, grad_fn=<DivBackward0>), 0.8797619047619047, 0.3875),\n",
              " (64, tensor(0.4413, grad_fn=<DivBackward0>), 0.8523809523809524, 0.3875),\n",
              " (65, tensor(0.4422, grad_fn=<DivBackward0>), 0.8285714285714286, 0.3875),\n",
              " (66, tensor(0.4476, grad_fn=<DivBackward0>), 0.8238095238095238, 0.375),\n",
              " (67, tensor(0.4644, grad_fn=<DivBackward0>), 0.8238095238095238, 0.3625),\n",
              " (68, tensor(0.5035, grad_fn=<DivBackward0>), 0.8261904761904761, 0.3625),\n",
              " (69, tensor(0.6283, grad_fn=<DivBackward0>), 0.9023809523809524, 0.425),\n",
              " (70, tensor(0.7302, grad_fn=<DivBackward0>), 0.7095238095238096, 0.375),\n",
              " (71, tensor(0.6921, grad_fn=<DivBackward0>), 0.9154761904761904, 0.4125),\n",
              " (72, tensor(0.7824, grad_fn=<DivBackward0>), 0.5583333333333333, 0.35),\n",
              " (73, tensor(0.8554, grad_fn=<DivBackward0>), 0.5880952380952381, 0.35),\n",
              " (74, tensor(0.9833, grad_fn=<DivBackward0>), 0.6452380952380953, 0.2375),\n",
              " (75, tensor(0.6954, grad_fn=<DivBackward0>), 0.6214285714285714, 0.275),\n",
              " (76, tensor(0.7996, grad_fn=<DivBackward0>), 0.7321428571428571, 0.4375),\n",
              " (77, tensor(0.7731, grad_fn=<DivBackward0>), 0.8535714285714285, 0.35),\n",
              " (78, tensor(0.5157, grad_fn=<DivBackward0>), 0.9023809523809524, 0.4),\n",
              " (79, tensor(0.3760, grad_fn=<DivBackward0>), 0.9535714285714286, 0.4125),\n",
              " (80, tensor(0.2977, grad_fn=<DivBackward0>), 0.9761904761904762, 0.5),\n",
              " (81, tensor(0.2792, grad_fn=<DivBackward0>), 0.9761904761904762, 0.45),\n",
              " (82, tensor(0.2795, grad_fn=<DivBackward0>), 0.9392857142857143, 0.4125),\n",
              " (83, tensor(0.2722, grad_fn=<DivBackward0>), 0.9404761904761905, 0.375),\n",
              " (84, tensor(0.2683, grad_fn=<DivBackward0>), 0.8559523809523809, 0.35),\n",
              " (85, tensor(0.3147, grad_fn=<DivBackward0>), 0.8797619047619047, 0.4125),\n",
              " (86, tensor(0.3643, grad_fn=<DivBackward0>), 0.6369047619047619, 0.3125),\n",
              " (87, tensor(0.5919, grad_fn=<DivBackward0>), 0.7297619047619047, 0.3125),\n",
              " (88, tensor(0.5265, grad_fn=<DivBackward0>), 0.8202380952380952, 0.5),\n",
              " (89, tensor(0.6221, grad_fn=<DivBackward0>), 0.7666666666666667, 0.4),\n",
              " (90, tensor(0.5683, grad_fn=<DivBackward0>), 0.8702380952380953, 0.3875),\n",
              " (91, tensor(0.3716, grad_fn=<DivBackward0>), 0.8702380952380953, 0.4125),\n",
              " (92, tensor(0.4029, grad_fn=<DivBackward0>), 0.9238095238095239, 0.375),\n",
              " (93, tensor(0.7844, grad_fn=<DivBackward0>), 0.888095238095238, 0.4375),\n",
              " (94, tensor(0.6507, grad_fn=<DivBackward0>), 0.7511904761904762, 0.3875),\n",
              " (95, tensor(0.7103, grad_fn=<DivBackward0>), 0.944047619047619, 0.475),\n",
              " (96, tensor(0.3907, grad_fn=<DivBackward0>), 0.8154761904761905, 0.4875),\n",
              " (97, tensor(0.8575, grad_fn=<DivBackward0>), 0.705952380952381, 0.375),\n",
              " (98, tensor(1.0462, grad_fn=<DivBackward0>), 0.6773809523809524, 0.5),\n",
              " (99, tensor(0.8881, grad_fn=<DivBackward0>), 0.9130952380952381, 0.45)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "finish the training function, and write the get accuracy function"
      ],
      "metadata": {
        "id": "4h1pRtqLT9-L"
      }
    }
  ]
}